<html>
<head>
<title>The Technopolis-Articles</title>
<link rel="stylesheet" type="text/css" href="css/style.css">

</head>
<body>

<h1> Articles </h1>


<div class="navbar">
  <a href="index.html">Home</a>
    <a href="#articles">Articles</a>
    <a href="contact.html">Contact</a> 
    </div>
  

</div>

<div class="search-container">
  <input type="text" placeholder="Search.." id="searchInput" oninput="handleInput()">
  <div id="searchResults"></div>
</div>

    
<div class="content">

  <div class="content">
  <button type="button" class="collapsible_article" id="Music: The Dark Side of Art?" >Music: The Dark Side of Art?</button>
    <div class="article_content">
        <p class="center">DISCLAIMER</p>
        <p class="center">The following article, although discussing a serious topic, examines it in a way that is philosophical and not meant to be taken completely seriously given its unscientific nature. However, I hope you have fun while reading this.</p>

        <p>Take a walk down Commonwealth Ave, through Mugar library, or any one of Boston University’s many study spots, and you’ll find that listening to music is very popular. Walking through any of these places without spotting someone with a headphone or earbuds in their ears would be a tall task for any given day. As you would expect, music isn’t just popular at Boston University. According to IFPI’s 2023 Global Music Report, there are 589 million paid subscription accounts to streaming services. </p>

        <p>Unfortunately, depression, especially among people ages 15-29, is also very prevalent. In 2019, researchers conducted a study on mood regulation and music. According to the study, suicide is the leading cause of death for this demographic globally and around 13% of Americans fit the DSM criteria for depression. Additionally, depression is especially dangerous among young people because if untreated, it can become a lifelong disability.</p>

        <p>As the article explains, the prevalence of depression and the digitalization of music has allowed music to become a popular coping mechanism for many young people. Yet research has shown that listening to music to help with mental issues has mixed results at best. The article continues by classifying coping methods into two categories: 1) listening to music that mirrored and intensified their current mood (which most participants adopted) and 2) listening to music that differed from their current mood.</p>
  
        <p>While listening to music that mirrored the participants’ emotions was more common, these participants were also generally least aware of how the music affected them. Counterintuitively, both of these methods “appeared to have negative outcomes at times and positive outcomes at other times.” The article suggests that understanding when music leads to these positive or negative outcomes requires further examination.
        </p>
    
        <p>The prevalence of music as a cathartic art form marks an interesting philosophical case in our relationship with music. Why is music such a great coping tool in some situations and ineffective or even detrimental in others? What is it about music that gives it such a cathartic quality to begin with? The subjective nature of art and its fundamental truths cannot be reached scientifically, so to answer this question, we turn to philosophy.</p>
    
        <p>Friedrich Nietzsche, a German philosopher, sought to answer this question in his book The Birth of Tragedy. Nietzsche believes that in all art there are two distinct elements: the Apollonian and the Dionysian. The Apollonian represents the principle of individuation; the serene, dream-like experience that an audience experiences from visual art. The Dionysian represents the intoxicating yet unifying experience that an audience experiences from music, where the individual is lost.</p>
    
        <p>This Dionysian element of music grants it its cathartic elements: unlike visual art, which takes audiences to a new world where each reality’s limits are fixed and solely an individual experience, music can cause people to lose a sense of individuality and act in ways that they would never in other social situations. Think about a party or a concert! Also, unlike the Apollonian, the Dionysian lies somewhere more grounded in reality, where audiences are more connected to their emotions, or what Nietzsche refers to as one’s “primal being.”
        </p>
    
        <p>This means that the Dionysian parallels reality in ways that the Apollonian could never in the same way that, as discussed earlier, it appears most people tend to listen to music that mirrors their own emotions, potentially intensifying it. Nietzsche’s theory also explains why listening to music different to current emotions doesn’t work because it doesn’t match reality. What’s important is that it seems that neither of the depression-coping strategies eliminate negative emotions. So is listening to music that intensifies negative emotions purely destructive?</p>
  
        <p>Aristotle answers this question in what he refers to as the “Paradox of Tragedy,” where unpleasant artistic experiences (he refers to tragic poems) can often be pleasurable to audiences. He explains that tragedy portrayed in art can evoke emotions of fear and pity, creating catharsis for audiences who are temporarily transported away from their own issues and, once they return back to reality, are able to accept their problems as facts of life.</p>

        <p>After considering the ideas of both Nietzsche and Aristotle, it seems that music can prove therapeutic in temporarily intensifying the negative emotions we experience as an expressive catharsis. Yet, like all things, this catharsis must be taken in moderation. If tragedy evokes fear and pity as Aristotle believes, then too much of this fear and pity will prove detrimental to the audience. For future research projects on music and mood regulation, a hypothesis to test might be that excessive music listening may be a maladaptive coping mechanism and a factor in the mixed results of musical therapy.</p>

        <p>The ability of music to influence our mood is much more nuanced than one might expect at first glance, and it seems in excess that it can be harmful to mental health. Using music to influence mood continues to be a popular coping tool, but its cathartic and Dionysian properties represent a dark part of art.
        </p>

        <p>References:</p>
        <p>Stewart, J., Garrido, S., Hense, C., & McFerran, K. Music Use for Mood Regulation: Self-Awareness and Conscious Listening Choices in Young People With Tendencies to Depression. National Library of Medicine: Frontiers in psychology, 2019. https://doi.org/10.3389/fpsyg.2019.01199.
        <br> Garrido, Sandra, and Emery Schubert. "Moody melodies: Do they cheer us up? A study of the effect of sad music on mood." Psychology of Music 43, no. 2 (2015): 244-261.
        <br>
        Cooper, D. E. (2019). Aesthetics (2nd ed.). Wiley Global Research (STMS). https://reader.yuzu.com/books/9781119116820
        </p>
        

        <p class="alignright">Author: Jericho Jacala<br></p>
          <br>
          <br>
          <br>
          <br>
             
  </div>

   <button type="button" class="collapsible_article" id="Getting our Fair Share: Thoughts on the AI Dividend" >Getting our Fair Share: Thoughts on the AI Dividend</button>
  <div class="article_content">
      <img src="docs/assets/JerryAIDivedendGraphic.png" alt="AI dividend Story Graphic" class="center" > 

        <p>At the end of September, OpenAI’s ChatGPT gained the ability to access the internet. Previously, the chatbot had a knowledge cutoff at September 2021, but Plus and Enterprise users now have the power of the internet at their fingertips. While this is groundbreaking news for generative AI, in an internet where data is king, where personal information is bought and sold by the truckload, what do these breakthroughs in AI mean for the average person?
        </p>

        <p>The constant growth of training data for publicly available generative AI systems improves the user experience for everyone. But this type of artificial intelligence is really only the tip of the iceberg. As we develop other models for applications such as marketing and law enforcement, much of artificial intelligence will (or already has) used public data to generate private gains that far exceed their public benefit. Since all models require public data for their production, then for all models we deserve a part of the benefits.
        </p>

        <p>One possible solution that has emerged is an AI Dividend. Big Tech companies would pay into a fund via a licensing plan. This fund is then equally and publicly distributed in exchange for using public information as training data. As technologists Bruce Schneier and Barath Raghavan, the creators of the idea, write, “Our plan can’t make sure there are no downsides to the development of AI, but it would ensure that all Americans will share in the upsides — particularly since this new technology isn’t possible without [the public’s] contribution.”</p>
  
        <p>Americans, and all people, should be able to take their share of the benefits from this new technology-but the idea of an AI Dividend needs some fleshing out. One major issue is that data inequality spans far more than just generative artificial intelligence. Before we ask ourselves if we should get a piece of the earnings, we (as a society) should ask ourselves, “Should I even let my data be collected?” Through the implementation of an AI Dividend, we legitimize the collection of our data instead of choosing to regulate it.
        </p>
    
        <p>The issues don’t stop there. Raghavan and Schneier both claim that, “...[the AI Dividend] isn’t an attempt to strangle this nascent technology,” referring to generative AI. Yet such a dividend, especially at this stage in its development, might do just that. Contrary to their claims, generative AI is expensive to develop and maintain. and worse, its path to profitability isn’t exactly clear. According to Gerrit De Vynck, a tech reporter for the Washington Post, Generative AI requires gigantic amounts of training data, necessitating specialized hardware, engineers, and powerful servers to run models. To make matters worse, Vynck also points out that the data provided by generative AI is unreliable: “Chatbots also make up false information and pass it off as real, a problem that the companies are trying to solve but some AI researchers say might not be possible to fix.” The bottom line is that generative AI is not a cheap technology but currently very expensive, and that an AI Dividend would inevitably impede the development of the technology at this point in time.</p>
    
        <p>Handing out licenses to use public data also begs the question, “What is public data?” Some examples are clear- census data, government spending, and criminal records are all readily available to the public. This data is made available by government bodies. Yet other entities, such as Instagram and Google, have made a living off of collecting data in exchange for a service. The public’s lack of compensation for its contribution in the production of generative AI, even AI in general, is only a small part of a much greater problem that the collection of our data is almost inescapable. Data is collected, bought, and sold by the ton through loyalty programs, search engines, and social media. The AI Dividend aims to compensate the public for the production of AI models when our data is used for so much more. In a world where corporations live and die on the collection of data from the public and staying in touch with their demographic, generative AI has become a scapegoat for the problem. In other words, if we want to implement a dividend to compensate people for their data, AI may be a great starting point, but to regulate artificial intelligence while allowing companies like Facebook and Google to continue to collect data for profit would be unfair.</p>
    
        <p>Despite these issues, such a dividend could potentially act as a Universal Basic Income, and one that only comes out of the pockets of Big Tech at that. Even here in the United States, there remains a large disparity between the digital infrastructure in different regions, specifically between richer and poorer communities. As automation and computing become more and more influential, giving people the capital they need to buy groceries, pay rent, and even cover business expenses- may help move the needle towards bridging that gap.
        </p>
    
        <p>Raghavan and Schneier remind us that we’ve regulated other natural resources for the public good in the past: “For four decades, Alaskans have opened their mailboxes to find checks waiting for them, their cut of the black gold beneath their feet” They refer to the Alaska Permanent Fund, which has allowed Alaskans to share in the benefits of oil in Alaska. The AI Dividend would handle the same issues in an AI-driven world. While still in its infancy, the implementation of an AI Dividend is worth considering.
        </p>

    <p>References:</p>
    <p>Arunasalam, Samrhitha. “CHATGPT Users Can Now Browse Internet, OpenAI Says.” Reuters, September 27, 2023. https://www.reuters.com/technology/openai-says-chatgpt-can-now-browse-internet-2023-09-27/#:~:text=Sept%2027%20(Reuters)%20%2D%20ChatGPT,its%20earlier%20September%202021%20cutoff.
    <br>Schneier, Bruce, and Barath Raghavan. “Artificial Intelligence Can’t Work without Our Data.” POLITICO, June 29, 2023. https://www.politico.com/news/magazine/2023/06/29/ai-pay-americans-data-00103648.
    <br>De Vynck, Gerrit. “Every Start-up Is an AI Company Now. Bubble Fears Are Growing.” The Washington Post, WP Company, 5 Aug. 2023, www.washingtonpost.com/technology/2023/08/05/ai-hype-bubble-chatgpt/. 
    <br>Schneier, Bruce, and Barath Raghavan. “Artificial Intelligence Can’t Work without Our Data.” POLITICO, June 29, 2023. https://www.politico.com/news/magazine/2023/06/29/ai-pay-americans-data-00103648. </p>
         
        
        
        
    
  
          <p class="alignright">Author: Jericho Jacala <br> Graphic: Anna LaPrade</p>
          <br>
          <br>
          <br>
          <br>
             
      
  </div>


  
    
<button type="button" class="collapsible_article" id="Morphowave Rollout Leaves The Student Body Confused" >Morphowave Rollout Leaves The Student Body Confused</button>
<div class="article_content">
    <img src="docs/assets/HoseArticleMorphowaveGraphic.png" alt="Hose Article Morphowave Graphic" class="center" > 

    <p>The rollout of Morphowave technology across BU dining halls has been a concerning effort on BU’s part. These funky-looking biometric scanners that supposedly speed up the process of dining hall entry have been a headache for many as many ask what the point of these new scanners are. Although it may not seem like it, these new biometric scanners give insight into an ever-increasing conflict arising between consumers and large corporations.</p>
   
    <p>Biometric scanning is becoming a prevalent way of accessing places or objects. Many people have fingerprint scanners or facial recognition on their phones or computers because of the convenience allotted by this software. As a result, many campuses are using this by implementing biometric scanners, like those of Morphowave, into daily student life. Yet the rollout of the technology here at Boston University has been not only forceful but without the consent of the student body. Here are a multitude of reasons, such as the lack of clarity from dining hall services about how extensive Morphowave tech would be used and the way these products have been pushed to students, as well as the potential consequences of giving this information to a third party are all great reasons for concern if you’re a student here at BU.</p>
   
    <p>There was immense confusion suffered by many as they strolled into Warren dining hall and saw a sign that signaled the end of the Terrier Card era and the beginning of the hand-waving era. Many were rightly taken aback as this shift in policy was concerning to those who had ethical concerns or just security concerns. The lack of transparency on BU’s part prompted members of Technopolis to reach out to the dining services to state and make our concerns known to the administration. Much to our surprise, after notifying BU Auxiliary Services of these concerns, we were notified by the Media Director they had no clue that such a policy was being marketed toward students as they stated, “There are no plans to phase out Terrier Cards on campus, including in the dining halls. The Morpho technology is simply another tool that students may use to gain entrance into our dining halls.” If the administration is not aware of the direct contradictions being made, then how can we as students trust the decisions being made behind the scenes?</p>

    <p>Furthermore, the amount of trust BU expects us to put into a biometric system is unrealistic. Regardless if biometric entry is a good or convenient way of going about our daily routines, the storage of biometric data has a greater chance of risk involved when using it. Assurances of safety were made by BU through an email explaining that “the Morphowave reader scans biometric points on your hand… these points are converted into binary code and your fingerprint scans are then deleted. These points are stored securely and cannot be translated back into fingerprints.” However, the true level of security comes into question as biometric data breaches are becoming more common as society becomes more reliant on these forms of security. Even if actions are taken to safeguard a user’s biometric information, it is still possible for corporations to sell this biometric data with or without a user’s consent. This is where a lot of modern legislation regarding biometric data comes into play. There are currently 6 states that have implemented legislation that protects a citizen’s right to unethical use of their biometric data (bclplaw). Biometric data collection is riskier than typical data collection because of the direct tie to a user’s person which makes the recovery of compromised data more difficult. You can always update passwords or documents; you cannot easily change your fingerprints or face(Bloomberg Law). The potential of biometric identity theft should terrify all who partake in this digitized world.</p>

    <p>Ultimately, BU’s decision to implement such a controversial technology has created confusion among the student body. The convenience of scanning your hand does not drastically outweigh the extra second it takes to swipe a card, as well as the higher risk biometrics pose. A switch to biometric scanners at a dorm entry point may be a better alternative, because once more what is the need for a biometric scanner when a student wants a sandwich?</p>
  
    <p>References:</p>
    <p>
        https://www.bclplaw.com/en-US/events-insights-news/us-biometric-laws-and-pending-legislation-tracker.html 
        https://pro.bloomberglaw.com/brief/biometric-data-privacy-laws/
        </p>

        <p class="alignright">Author: Jose Lopez <br> Graphic: Anna LaPrade</p></p
        <br>
        <br>
        <br>
        <br>
           
    
</div>

<button type="button" class="collapsible_article" id="The Herculean Task of Detecting ChatGPT's Writing">The Herculean Task of Detecting ChatGPT's Writing</button>
<div class="article_content">
    <img src="docs/assets/ChatGPTStoryGraphic.png" alt="Chat GPT Story Graphic" class="center" >

    <p>In the era of advanced artificial intelligence, distinguishing between human and AI-generated text has emerged as an intricate puzzle, with ChatGPT at its heart. This powerful language model poses an exceptionally challenging task when it comes to identifying its outputs, owing to its design that withholds access to responses across chats and the infinite array of prompts users can input.</p>

    One of the central obstacles in recognizing ChatGPT's work lies in its astonishing adaptability. The model can seamlessly mold its writing style to fit various contexts, rendering it nearly indistinguishable from human-generated content. This adaptability is a result of extensive training on a diverse dataset, enabling ChatGPT to produce context-aware responses that blur the lines between human and AI-generated text.
    <br>
    <br>
    Adding to the complexity is ChatGPT's design, which refrains from providing access to responses across different chat sessions. Each interaction with the model exists in isolation, without a window into its prior responses or prompts from other users. This intrinsic lack of transparency hinders efforts to uncover patterns that could reveal AI-authored content.
    <br>
    <br>
    Compounding the challenge is the fact that users can input an endless variety of prompts into ChatGPT. From innocuous queries to potentially harmful content, the sheer volume of possible inputs makes identifying ChatGPT's contributions within this vast ocean of interactions an immensely formidable task.
    <br>
    <br>
    In the face of these daunting hurdles, researchers and developers continue to grapple with inventive approaches to distinguish AI-generated text from human writing. However, as models like ChatGPT persistently evolve and adapt, the task of identifying their work remains a Herculean endeavor, highlighting the ever-expanding complexity of AI in our digital world.
    <br>
    <br>
    Did you notice this article was written by ChatGPT? If not, point proven! At this point, AI written content can be nearly unintelligible from its human-created counterpart. Imagine how difficult it could become with further AI development!
    <br>
    <br>
    
    <p class="alignright">Author: Chat GPT ;)<br>Graphic: Anna LaPrade </p>
    <br>
    <br>
    <br>
    <br>

</div>
    
</div>

<script>
      function handleInput() {
            var searchInput = document.getElementById('searchInput');
            var searchResults = document.getElementById('searchResults');
            var content = document.getElementsByClassName('collapsible_article');
            var searchText = searchInput.value.toLowerCase();

            if (searchText === '') {
                searchResults.innerHTML = '';
                return;
            }

            searchResults.innerHTML = '';

            
            for (var i = 0; i < content.length; i++) {
                var articleId = content[i].id.toLowerCase();
                
                if (articleId.includes(searchText)) {
                    
                    var button = document.createElement('button');

                    button.className = 'search-result-button';

                    var buttonText = articleId.length > 20 ? articleId.substring(0, 20) + '...' : articleId;

                    button.textContent = buttonText;
                    button.onclick = goToArticle.bind(null, content[i].id);
                    button.className = 'newbutton';

                    searchResults.appendChild(button);
                }
            }
        }

    function goToArticle(articleId) {
    var articleElement = document.getElementById(articleId);

    if (articleElement) {
      articleElement.classList.add('highlighted');
      articleElement.scrollIntoView({ behavior: 'smooth', block: 'center' });

       setTimeout(function () {
            articleElement.classList.remove('highlighted');
        }, 2000);
    }
}

    
    var coll = document.getElementsByClassName("collapsible_article");
    var i;
    
    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
          content.style.display = "none";
        } else {
          content.style.display = "block";
        }
      });
    }
</script>



</body>
</html>
